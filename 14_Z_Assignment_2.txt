Learning Objectives:-
Find the broken pod and save the pod name to the file `/home/cloud_user/debug/broken-pod-name.txt`
In the same namespace as the broken pod, find out which pod is using the most CPU and output the name of that pod to the file `/home/cloud_user/debug/high-cpu-pod-name.txt`
Get the broken pod's summary data in the JSON format and output it to the file `/home/cloud_user/debug/broken-pod-summary.json`
Get the broken pod's container logs and output them to the file `/home/cloud_user/debug/broken-pod-logs.log`
Fix the problem with the broken pod so that it enters the `Running` state



Problem Statement:-
You recently got a new job at a company that has a robust Kubernetes infrastructure used by multiple teams. Congratulations! However, you were just told by the team that there is a problem with a service they use in the cluster and they want you to fix it. Unfortunately, no one is able to give you much information about the service. You don't even know what it is called or where it is located. All you know is there is likely a pod failing somewhere.

Your team has asked you to take the lead in debugging the issue. They want you to locate the problem and collect some relevant debugging information that will help the team analyze the problem and correct it in the future. They also want you to go ahead and get the broken pod running again.

You will need to do the following:

Find the broken pod and save the pod name to the file /home/cloud_user/debug/broken-pod-name.txt.
In the same namespace as the broken pod, find out which pod is using the most CPU and output the name of that pod to the file /home/cloud_user/debug/high-cpu-pod-name.txt.
Get the broken pod's summary data in the JSON format and output it to the file /home/cloud_user/debug/broken-pod-summary.json.
Get the broken pod's container logs and output them to the file /home/cloud_user/debug/broken-pod-logs.log.
Fix the problem with the broken pod so that it enters the Running state.

-----------------------------------------------------------------------------------------------------------------------------

master $ kubectl create ns web
namespace/web created
master $ vi my-web.yml

apiVersion: v1
kind: Pod
metadata:
  name: my-web
  namespace: web
  labels:
    app: myweb
spec:
  containers:
  - name: myweb-container
    image: nginx
    ports:
       - containerPort: 80
    command: ['sh','-c','nginx', '-g daemon off','-q']

giving bad command to make the pod not in running state

master $ kubectl apply -f my-web.yml
pod/my-web created
master $ kubectl get po my-web -n web
NAME     READY   STATUS      RESTARTS   AGE
my-web   0/1     Completed   2          27s
master $ kubectl get pod my-web -n web -o name > broken-pod-name.txt
master $ ls
broken-pod-name.txt  my-web.yml
master $ pwd
/root
master $ vi broken-pod-name.txt
master $ kubectl top pod >high-cpu-pod-name.txt
Error from server (NotFound): the server could not find the requested resource (get services http:heapster:)
master $ git clone https://github.com/linuxacademy/metrics-server
Cloning into 'metrics-server'...
remote: Enumerating objects: 9589, done.
remote: Total 9589 (delta 0), reused 0 (delta 0), pack-reused 9589
Receiving objects: 100% (9589/9589), 11.23 MiB | 1.94 MiB/s, done.
Resolving deltas: 100% (4853/4853), done.
Checking connectivity... done.
master $ kubectl apply -f metrics-server/deploy/1.8+/
clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created
clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator created
rolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader created
apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created
serviceaccount/metrics-server created
deployment.extensions/metrics-server created
service/metrics-server created
clusterrole.rbac.authorization.k8s.io/system:metrics-server created
clusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created
master $ kubectl get --raw /apis/metrics.k8s.io/
{"kind":"APIGroup","apiVersion":"v1","name":"metrics.k8s.io","versions":[{"groupVersion":"metrics.k8s.io/v1beta1","version":"v1beta1"}],"preferredVersion":{"groupVersion":"metrics.k8s.io/v1beta1","version":"v1beta1"}}
master $ kubectl top pod >high-cpu-pod-name.txt
master $ ls
broken-pod-name.txt  high-cpu-pod-name.txt  metrics-server  my-web.yml
master $ cat high-cpu-pod-name.txt
master $ vi high-cpu-pod-name.txt
master $ vi nginx-web.yml
master $ kubectl apply -f high-cpu-pod-name.txt
error: no objects passed to apply
master $ kubectl apply -f nginx-web
error: the path "nginx-web" does not exist
master $ kubectl apply -f nginx-web.yml
pod/nginx-web created
master $ kubectl top pod >high-cpu-pod-name.txt
master $ cat high-cpu-pod-name.txt
master $ ls
broken-pod-name.txt  high-cpu-pod-name.txt  metrics-server  my-web.yml  nginx-web.yml
master $ vi metrics-server
master $ kubectl top pods
master $ kubectl top pod nginx-web -n web
NAME        CPU(cores)   MEMORY(bytes)
nginx-web   0m           1Mi
master $ kubectl get po
No resources found.
master $ kubectl get pod
No resources found.
master $ kubectl get ns web
NAME   STATUS   AGE
web    Active   12m
master $ kubectl get po my-web -n web
NAME     READY   STATUS             RESTARTS   AGE
my-web   0/1     CrashLoopBackOff   7          11m
master $
master $ kubectl get pod my-web -n web -o json > broken-pod-summary.json
master $ cat broken-pod-summary.json
{
    "apiVersion": "v1",
    "kind": "Pod",
    "metadata": {
        "annotations": {
            "kubectl.kubernetes.io/last-applied-configuration": "{\"apiVersion\":\"v1\",\"kind\":\"Pod\",\"metadata\":{\"annotations\":{},\"labels\":{\"app\":\"myweb\"},\"name\":\"my-web\",\"namespace\":\"web\"},\"spec\":{\"containers\":[{\"command\":[\"sh\",\"-c\",\"nginx\",\"-g daemon off\",\"-q\"],\"image\":\"nginx\",\"name\":\"myweb-container\",\"ports\":[{\"containerPort\":80}]}]}}\n"
        },
        "creationTimestamp": "2019-11-28T00:43:47Z",
        "labels": {
            "app": "myweb"
        },
        "name": "my-web",
        "namespace": "web",
        "resourceVersion": "2908",
        "selfLink": "/api/v1/namespaces/web/pods/my-web",
        "uid": "239c3bf0-1178-11ea-92ce-0242ac110007"
    },
    "spec": {
        "containers": [
            {
                "command": [
                    "sh",
                    "-c",
                    "nginx",
                    "-g daemon off",
                    "-q"
                ],
                "image": "nginx",
                "imagePullPolicy": "Always",
                "name": "myweb-container",
                "ports": [
                    {
                        "containerPort": 80,
                        "protocol": "TCP"
                    }
                ],
                "resources": {},
                "terminationMessagePath": "/dev/termination-log",
                "terminationMessagePolicy": "File",
                "volumeMounts": [
                    {
                        "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                        "name": "default-token-4lsln",
                        "readOnly": true
                    }
                ]
            }
        ],
        "dnsPolicy": "ClusterFirst",
        "enableServiceLinks": true,
        "nodeName": "node01",
        "priority": 0,
        "restartPolicy": "Always",
        "schedulerName": "default-scheduler",
        "securityContext": {},
        "serviceAccount": "default",
        "serviceAccountName": "default",
        "terminationGracePeriodSeconds": 30,
        "tolerations": [
            {
                "effect": "NoExecute",
                "key": "node.kubernetes.io/not-ready",
                "operator": "Exists",
                "tolerationSeconds": 300
            },
            {
                "effect": "NoExecute",
                "key": "node.kubernetes.io/unreachable",
                "operator": "Exists",
                "tolerationSeconds": 300
            }
        ],
        "volumes": [
            {
                "name": "default-token-4lsln",
                "secret": {
                    "defaultMode": 420,
                    "secretName": "default-token-4lsln"
                }
            }
        ]
    },
    "status": {
        "conditions": [
            {
                "lastProbeTime": null,
                "lastTransitionTime": "2019-11-28T00:43:49Z",
                "status": "True",
                "type": "Initialized"
            },
            {
                "lastProbeTime": null,
                "lastTransitionTime": "2019-11-28T00:43:49Z",
                "message": "containers with unready status: [myweb-container]",
                "reason": "ContainersNotReady",
                "status": "False",
                "type": "Ready"
            },
            {
                "lastProbeTime": null,
                "lastTransitionTime": "2019-11-28T00:43:49Z",
                "message": "containers with unready status: [myweb-container]",
                "reason": "ContainersNotReady",
                "status": "False",
                "type": "ContainersReady"
            },
            {
                "lastProbeTime": null,
                "lastTransitionTime": "2019-11-28T00:43:47Z",
                "status": "True",
                "type": "PodScheduled"
            }
        ],
        "containerStatuses": [
            {
                "containerID": "docker://50141434d988762a817c6f1141d0606dc97ee4bdec27c54a8fad264e9fa1b51b",
                "image": "nginx:latest",
                "imageID": "docker-pullable://nginx@sha256:50cf965a6e08ec5784009d0fccb380fc479826b6e0e65684d9879170a9df8566",
                "lastState": {
                    "terminated": {
                        "containerID": "docker://50141434d988762a817c6f1141d0606dc97ee4bdec27c54a8fad264e9fa1b51b",
                        "exitCode": 0,
                        "finishedAt": "2019-11-28T00:54:45Z",
                        "reason": "Completed",
                        "startedAt": "2019-11-28T00:54:45Z"
                    }
                },
                "name": "myweb-container",
                "ready": false,
                "restartCount": 7,
                "state": {
                    "waiting": {
                        "message": "Back-off 5m0s restarting failed container=myweb-container pod=my-web_web(239c3bf0-1178-11ea-92ce-0242ac110007)",
                        "reason": "CrashLoopBackOff"
                    }
                }
            }
        ],
        "hostIP": "172.17.0.15",
        "phase": "Running",
        "podIP": "10.32.0.2",
        "qosClass": "BestEffort",
        "startTime": "2019-11-28T00:43:49Z"
    }
}